{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection\n",
    "\n",
    "* We uses the built-in Haar cascade classifiers in OpenCV\n",
    "* these classifiers have already been pre-trained to recognize faces!\n",
    "* Building our own classifier is certainly outside the scope of this case study. But if we wanted to, we would need a lot of “positive” and “negative” images. Positive images would contain images with faces, whereas negative images would contain images without faces.\n",
    "* Based on this dataset, we could then extract features to characterize the face (or lack of face) in an image and build our own classifier. It would be a lot work, and very time consuming.\n",
    "* Anyway, these classifiers work by scanning an image from\n",
    "* left to right, and top to bottom, at varying scale sizes. Scanning an image from left to right and top to bottom is called the **“sliding window”** approach.\n",
    "* As the window moves from left to right and top to bottom, one pixel at a time, the classifier is asked whether or not it **“thinks”** there is a face in the current window, based on the parameters that we have supplied to the classifier\n",
    "* Line 1 of the code defines FaceDetector class, which will encapsulate all the necessary logic to perform face detection.\n",
    "* In **facedetector.py** the first method defines the constructor on Line 3 which takes a single parameter – the path to where his cascade classifier lives. This classifier is serialized as an XML file. Making a call to cv2.CascadeClassifier will deserialize the classifier, load it into memory, and allow us to detect faces in images.\n",
    "* In **facedetector.py** the second method defines detect. This function takes one required parameter, the image that he wants to find the faces in, followed by three optional arguments. Let’s take a look at what these arguments mean:\n",
    "    1. scaleFactor: How much the image size is reduced at each image scale. This value is used to create the scale pyramid. In order to detect faces at multiple scales in the image (some faces may be closer to the foreground, and thus be larger, other faces may be smaller and in the background, thus the usage of varying scales). A value of 1.05 indicates that, we are reducing the size of the image by 5% at each level in the pyramid.\n",
    "    2. minNeighbors: How many neighbors each window should have for the area in the window to be considered a face. The cascade classifier will detect multiple windows around a face. This parameter controls how any rectangles (neighbors) need to be detected for the window to be labeled a face.\n",
    "    3. minSize: A tuple of width and height (in pixels) indicating the minimum size of the window. Bounding boxes smaller than this size are ignored. It is a good idea to start with (30, 30) and fine tune from there.\n",
    "\n",
    "* Detecting the actual faces in the image is handled on Line 8 by making a call to the detectMultiScale method of our classifier created in the constructor of the FaceDetector class. We supplies the scaleFactor, minNeighbors, and minSize, then the method takes care of the entire face detection process for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 face(s) found\n"
     ]
    }
   ],
   "source": [
    "from utilities.facedetector import FaceDetector\n",
    "import cv2\n",
    "\n",
    "# Define paths\n",
    "image_path = 'images/obama2.png'\n",
    "cascade_path = 'cascades/haarcascade_frontalface_default.xml'\n",
    "\n",
    "# Load the image and convert it to greyscale\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find faces in the image\n",
    "detector = FaceDetector(cascade_path)\n",
    "face_boxes = detector.detect(gray, 1.2, 5)\n",
    "print(\"{} face(s) found\".format(len(face_boxes)))\n",
    "\n",
    "# Loop over the faces and draw a rectangle around each\n",
    "for (x, y, w, h) in face_boxes:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Show the detected faces\n",
    "cv2.imshow(\"Faces\", image)\n",
    "if(cv2.waitKey(0)):\n",
    " cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Face Tracking\n",
    "\n",
    "### Face Detector Class\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "\n",
    "class FaceDetector:\n",
    "    def __init__(self, face_cascade_path):\n",
    "        # Load the face detector\n",
    "        self.face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "\n",
    "    def detect(self, image, scale_factor=1.1, min_neighbors=5):\n",
    "        # Detect faces in the image\n",
    "        boxes = self.face_cascade.detectMultiScale(image, scale_factor, min_neighbors, flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        # Return the bounding boxes\n",
    "        return boxes\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.facedetector import FaceDetector\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "# Define paths\n",
    "# video_path = 'video/adrian_face.mov'\n",
    "cascade_path = 'cascades/haarcascade_frontalface_default.xml'\n",
    "\n",
    "# Construct the face detector\n",
    "detector = FaceDetector(cascade_path)\n",
    "\n",
    "# Load the video\n",
    "# camera = cv2.VideoCapture(video_path)\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab the current frame\n",
    "    (ok, frame) = camera.read()\n",
    "\n",
    "    # If a frame does not exist, video is over\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Resize the frame and convert it to greyscale\n",
    "    frame = imutils.resize(frame, width=300)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image and clone the frame\n",
    "    face_boxes = detector.detect(gray, 1.1, 5)\n",
    "    clone = frame.copy()\n",
    "\n",
    "    # Draw the face bounding boxes\n",
    "    for (x, y, w, h) in face_boxes:\n",
    "        cv2.rectangle(clone, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show our detected faces\n",
    "    cv2.imshow(\"Face\", clone)\n",
    "\n",
    "    # Ff the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Tracking\n",
    "\n",
    "* We defined our EyeTracker class on Line 3 and the constructor on Line 4.\n",
    "* Our EyeTracker class takes two faceCascadePath and eyeCascadePath. The first is the path to the built-on face cascade classifier in OpenCV. The second is the path to the eye cascade classifier.\n",
    "* She then loads both classifiers of disk using the cv2.CascadeClassifier function on Lines 5 and 6.\n",
    "* From there, we can define the track method which is used to find the eyes in the image. This method takes only a single parameter – the image that contains the face and eyes she wants to track.\n",
    "* Then we can call the detectMultiScale method (Line 9) of our faceCascade classifier. This method returns to her the bounding box locations (i.e. the x, y, width, and height) of each face in the image.\n",
    "* We can then extracts the face Region of Interest (ROI) from the image on Line 16 using NumPy array slicing. The **faceROI** variable now contains the bounding box region of the face.\n",
    "* This time, we makes a call to the detectMultiScale method of the eyeCascade on Line 19, giving us a list of locations in the image where eyes appear.\n",
    "* We uses a much larger value of minNeighbors on Line 20 since the eye cascade tends to generate more false-positives than other classifiers.\n",
    "* Then, we loops over the bounding box regions of the eyes on Line 24, and updates her list of bounding box rectangles on Line 25.Finally, the list of bounding boxes is returned to the caller on Line 28.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "class EyeTracker:\n",
    "    def __init__(self, face_cascade_path, eye_cascade_path):\n",
    "        # load the face and eye detector\n",
    "        self.face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "        self.eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
    "\n",
    "    def track(self, image):\n",
    "        # Detect faces in the image and initialize the list of rectangles containing the faces and eyes\n",
    "        face_boxes = self.face_cascade.detectMultiScale(image, 1.1, 5)\n",
    "        boxes = []\n",
    "\n",
    "        # Loop over the face bounding boxes\n",
    "        for (f_x, f_y, f_w, f_h) in face_boxes:\n",
    "            # Extract the face ROI and update the list of bounding boxes\n",
    "            face_roi = image[f_y:f_y + f_h, f_x:f_x + f_w]\n",
    "            boxes.append((f_x, f_y, f_x + f_w, f_y + f_h))\n",
    "\n",
    "            # Detect eyes in the face ROI\n",
    "            eye_boxes = self.eye_cascade.detectMultiScale(face_roi, 1.1, 10)\n",
    "\n",
    "            # Loop over the eye bounding boxes\n",
    "            for (e_x, e_y, e_w, e_h) in eye_boxes:\n",
    "                # Update the list of bounding boxes\n",
    "                boxes.append((f_x + e_x, f_y + e_y, f_x + e_x + e_w, f_y + e_y + e_h))\n",
    "\n",
    "        # Return the bounding boxes around the faces and eyes\n",
    "        return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.eyetracker import EyeTracker\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "# Define paths\n",
    "# video_path = 'video/adrian_eyes.mov'\n",
    "face_cascade_path = 'cascades/haarcascade_frontalface_default.xml'\n",
    "eye_cascade_path = 'cascades/haarcascade_eye.xml'\n",
    "\n",
    "# construct the eye tracker\n",
    "eye_tracker = EyeTracker(face_cascade_path, eye_cascade_path)\n",
    "\n",
    "# Load the video\n",
    "# camera = cv2.VideoCapture(video_path)\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab the current frame\n",
    "    (ok, frame) = camera.read()\n",
    "\n",
    "    # Check if at the end of the video\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Resize the frame and convert it to greyscale\n",
    "    # Inorder to make system more faster\n",
    "    frame = imutils.resize(frame, width=300)\n",
    "    # Convertingto grayscale tends to increase the accuracy of the cascade classifiers.\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces and eyes in the image\n",
    "    boxes = eye_tracker.track(gray)\n",
    "\n",
    "    # Draw the face bounding boxes\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the tracked eyes and face\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    # If the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
